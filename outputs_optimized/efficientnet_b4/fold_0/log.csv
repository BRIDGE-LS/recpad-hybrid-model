train_loss,val_loss,val_macro_f1
1.0178667018413543,0.5961677625167127,0.6104036115796888
0.6128569262027741,0.5022081354138802,0.6563214032299372
0.5265921202557428,0.45330401707668694,0.6842561897917675
0.470819344997406,0.4251506601137166,0.7022500248293415
0.43464888615267616,0.4069642599444,0.7199139018465732
0.40410862436464856,0.3969648627146166,0.7256669047062614
0.37516006587232864,0.38250531336026533,0.7356668062846394
0.3475643406084606,0.37337428937685124,0.7356482700879603
0.3248509688632829,0.3676158284236278,0.7449800935352162
0.3047268196088927,0.36489073240331243,0.7408081454150567
0.28088046387263704,0.3628569756235395,0.7464350589877138
0.2635829606822559,0.3628957815734403,0.7449120861458073
0.24290062654018402,0.3672779073406543,0.7463644115786444
0.2228083576985768,0.37540601486606257,0.750329136251711
0.205762908999409,0.3773841220239291,0.7514676020815949
0.192097180553845,0.3790991612691052,0.7392155002711331
0.17687177833276135,0.3832706689872608,0.7448487188057628
0.16124578993873936,0.406264925480117,0.7489199711588433
0.1501087687398706,0.40051517633208056,0.7458699999787988
0.13261791356972286,0.4137181652025605,0.7423085892605121
0.12366503922854151,0.41668975131814273,0.74681245401397
0.11423200834436076,0.422992843640398,0.7428649886710161
0.11185553312408072,0.42950581054070164,0.7455495695882701
0.10147932299865144,0.4408140788234922,0.7491323873752196
0.09956110586971044,0.45053016577790284,0.7469802536990324
