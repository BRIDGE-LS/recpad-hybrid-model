train_loss,val_loss,val_macro_f1
1.0020579943316323,0.5937605256176725,0.6050794568269993
0.5986294224262237,0.482491278222629,0.6630002354486759
0.5221837861708233,0.44955362964953693,0.6870583201786482
0.4700669919763293,0.414421732328376,0.7018629753077154
0.4311843842608588,0.40119603511934376,0.7153551888242402
0.3978547501223428,0.3859476372599602,0.7209922736490313
0.3748436710664204,0.37982198953324436,0.7249788580896503
0.34695829144545964,0.36728529670104687,0.7382792124165507
0.3227013137425695,0.3638258118714605,0.735415848657097
0.29737926283904487,0.35930820166760563,0.7421050626041695
0.2768979023354394,0.361839831863739,0.7414437973038517
0.25885004938926015,0.3688158882135639,0.7397073681519775
0.23739813534702572,0.36026485743267195,0.7425199230618438
0.21925441609110152,0.37381755024650876,0.7360637245578583
0.20282264949594225,0.3751333322452039,0.7456034579604842
0.18421072085840362,0.3785572993968214,0.7418070097929464
0.1680753698859896,0.39288358420741804,0.7451136336280829
0.156261729949287,0.40009480129395214,0.7415950064582815
0.1429210302978754,0.4176122702620163,0.7336604858358264
0.13249415176893983,0.41729854005483946,0.7393474106737091
0.12289842294688735,0.42388124178562847,0.7411201518358536
0.11286928542703391,0.42667523452213835,0.7395957356726897
0.10433570689601558,0.4301949268473046,0.7396210200471804
0.10031163347938231,0.42989855464928006,0.7402613060382657
0.09777271578886679,0.43532370190535274,0.7401008139853578
