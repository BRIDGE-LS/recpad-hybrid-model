train_loss,val_loss,val_macro_f1
1.0095417227404457,0.588917193592203,0.6088329238726025
0.6181208654471806,0.4857340608628429,0.6625365208174486
0.5358037303345544,0.45504138618707657,0.6758966851897676
0.4811059560946056,0.42872296836303203,0.6868206079328294
0.4401110781942095,0.4076442973954337,0.7009364573928046
0.40623742469719476,0.3897396940357831,0.7134323224226415
0.3798575693879809,0.3758150397666863,0.725346492934186
0.35455634685925075,0.3710381184913674,0.7294350024316065
0.32719514837435315,0.36969957766788347,0.7256694868549745
0.31047331669500894,0.3619225862226924,0.7346965728583899
0.28178904356275286,0.35629086614567407,0.7360927568613512
0.2629331301535879,0.3624332371947108,0.7371142571431561
0.24790924483537674,0.3589556525860514,0.744420436846533
0.2218687102666923,0.3619531421561022,0.7445935037172702
0.20808904177376203,0.37201247371885243,0.7429344840327334
0.18990090907897267,0.3719118928574786,0.7398117046486915
0.17910444130854947,0.3804242203050122,0.7442231213044869
0.1625265495883567,0.3879735511632598,0.7453156060746018
0.15060985314420292,0.4015806488388655,0.7339913727970373
0.1357711876843657,0.4055780029418517,0.739743627814328
0.12743539629237993,0.41721215026871283,0.7381699170814984
0.11494552147707769,0.42431382181084887,0.7391950905211597
0.10843706690094301,0.43721944196339774,0.7361098262531951
0.09676153115076679,0.44788198842077837,0.733359275161668
0.09063523217716388,0.4490926878108662,0.7406741034336582
0.08819263099400061,0.46273572199350715,0.7347344451443318
0.08474559115299157,0.4582043306483906,0.7330140576033921
0.08168739876523613,0.4609897862359577,0.7403476208191087
