train_loss,val_loss,val_macro_f1
0.9850909936428071,0.5663377718657864,0.6235568345018669
0.6163813030038561,0.46552555764816245,0.6792097690156272
0.535749155317034,0.4251756443813139,0.7015872617259342
0.47940819099971227,0.40239256392328104,0.7108689366346972
0.44377436908653806,0.38226775840228916,0.7230773879395875
0.4084191816704614,0.37267930015009276,0.7241973816961631
0.3812087443130357,0.3560355031216631,0.7335585818587669
0.35110793217590874,0.3469528583239536,0.7417784584644287
0.3309097220982824,0.3382834202172805,0.7438599015305003
0.3056642231345177,0.3341399327832825,0.7500858960695422
0.2860794277361461,0.33541390315002323,0.74832931438109
0.2648902119057519,0.33285183353083475,0.7509246403588257
0.2458624944303717,0.3385251590183803,0.7545435205311051
0.2256609516441822,0.3390946619554746,0.7541064600790643
0.21145910346933774,0.3371466088051699,0.759495233072723
0.19384443663699286,0.342948450896965,0.7567498506200419
0.18161736505372184,0.35166063309856216,0.7569773741417949
0.1610415597132274,0.3604907068823065,0.7540970680724024
0.14962933374941348,0.36478561641914503,0.7558634357227145
0.14146212936512062,0.3742366331648462,0.7516227895427723
0.12863301228199686,0.3777658883862349,0.755789010565523
0.11559394383217607,0.39707360043171414,0.7489235398146629
0.11138757878967694,0.3884142570349635,0.755690991967567
0.10504625566516604,0.395954227017961,0.7511668207277297
0.10320893465088947,0.39381421798345995,0.7522467697082951
