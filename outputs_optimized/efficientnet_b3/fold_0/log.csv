train_loss,val_loss,val_macro_f1
0.7214553379842213,0.4346206837466785,0.7005378357969503
0.4273709424223219,0.3827837420703501,0.7306917678106944
0.3322698720267841,0.3571723562722303,0.7466199208700023
0.262679738513061,0.35331488803637273,0.7520256162822826
0.20515245254550663,0.357654406023877,0.7456405007387841
0.15162660961065974,0.38429091030693785,0.7499539612369628
0.12310330268102032,0.3943992972335949,0.7503667018027744
0.09283963968604803,0.41738140499409365,0.74418893441869
0.07956438122796161,0.44032694825104307,0.7546609037612106
0.06463206183644278,0.46434272751592254,0.7448059018352222
0.05353397435428841,0.46943492256104946,0.7499728375646798
0.04795981191537742,0.48442143944985405,0.7423649543024107
0.04053627311704414,0.5142854092338559,0.7463695796736689
0.042392322278182425,0.49771313080374074,0.749517625960384
0.03652825707899007,0.5153182524123362,0.745022901794381
0.028588605260343423,0.513303124279316,0.7558544163937564
0.024113166585165473,0.5320161132484066,0.7465006526136051
0.022654781586424047,0.5225074871500232,0.7504960695906507
0.021706135767146147,0.5318959183534797,0.7546955228668235
0.01828556467078826,0.5391639407857188,0.7529788357731009
0.019834727441717406,0.5437535787077279,0.743384539108898
0.018281786339989465,0.5547545366440615,0.749970486074045
0.01408914881893101,0.5444033689445302,0.7512250371517557
0.013942400625927673,0.5664165060306728,0.7518253841371458
0.014166209986865786,0.5563149950419534,0.7496779309510742
0.014006552950761813,0.5575870837617133,0.7476746347874872
