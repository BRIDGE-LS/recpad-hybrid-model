train_loss,val_loss,val_macro_f1
0.7113398084470204,0.4238793373259963,0.7137604107629901
0.42680233112403326,0.3565461386223229,0.7406823230109627
0.3337737235086305,0.33754771016538143,0.7487527653321657
0.2623190564938954,0.33552415767798616,0.7572608124423468
0.20501281494327953,0.3431885316967964,0.757273325547336
0.15832013914840562,0.3604436359577337,0.7605624594755963
0.12086210763241563,0.39302314652548154,0.7505570102415899
0.09936741321746792,0.39366069534907533,0.7572212510315076
0.07842886035091111,0.4186535668179241,0.7538554780920794
0.06408365157193371,0.4283756963595064,0.762365493470346
0.05615331881812641,0.4515624563494811,0.7616877429249977
0.048947600660845636,0.46275606499367145,0.7563302112351828
0.04344448740461043,0.48301024790093,0.7556535719044986
0.038234908814342425,0.47601988187477906,0.7566330896072418
0.03572433558665216,0.49216249299102593,0.7568237908210782
0.034106697887780944,0.4965952692401348,0.7632505234172182
0.026232583214412443,0.5038220667831448,0.7610642902026239
0.02664016516335375,0.5334453818777918,0.7577572135178465
0.027955632050122532,0.5420829529721974,0.7521548926220682
0.025250286472528905,0.5117380348490361,0.7614883381814186
0.023865692485389965,0.5146216901057229,0.7590253614421176
0.020159750811057166,0.5342861426405,0.7578214548594127
0.01829749653207338,0.526449537436877,0.758111126273078
0.014072791110632742,0.5477303458586791,0.7580700994393297
0.01402139589539729,0.5494736605799015,0.7552030770671803
0.013775172010513155,0.560701076146833,0.7556491334811325
