# Sistema de Ensemble MorfolÃ³gico com EfficientNet para ClassificaÃ§Ã£o de Tecidos Tumorais GÃ¡stricos

## VisÃ£o Geral do Projeto

Este projeto implementa um sistema de classificaÃ§Ã£o baseado em deep learning para anÃ¡lise do microambiente tumoral em lÃ¢minas histopatolÃ³gicas com coloraÃ§Ã£o H\&E. O sistema Ã© baseado em um ensemble morfolÃ³gico de modelos EfficientNet-B0, B3 e B4, com suporte a empilhamento (stacked generalization) e comparaÃ§Ã£o estatÃ­stica(DemÅ¡ar2006 e Wolpert1992).

---

## Justificativas TeÃ³ricas e Arquiteturais

### 1. Uso de Ensembles na ClassificaÃ§Ã£o HistopatolÃ³gica

**FundamentaÃ§Ã£o:** Ensembles sÃ£o conhecidos por melhorar a acurÃ¡cia e robustez de sistemas de classificaÃ§Ã£o ao combinar a diversidade de modelos base (Ã‡ataltepe et al., 2003; Dietterich, 2000). Wolpert (1992) introduz o conceito de *stacked generalization* como alternativa superior ao simples voto, ao aprender uma regra de combinaÃ§Ã£o baseada em um meta-aprendizado.

**DecisÃ£o Arquitetural:** Implementa-se um ensemble com duas formas de agregaÃ§Ã£o:

* Soft-voting ponderado por desempenho das folds
* Stacking com um meta-modelo (regressÃ£o logÃ­stica ou MLP leve)

---

### 2. SeleÃ§Ã£o dos Modelos EfficientNet-B0, B3 e B4

**FundamentaÃ§Ã£o:** A arquitetura EfficientNet (Tan & Le, 2019) permite escala balanceada de profundidade, largura e resoluÃ§Ã£o. Modelos com diferentes escalas sÃ£o sensÃ­veis a diferentes padrÃµes morfolÃ³gicos (Tellez et al., 2019; Liang et al., 2023).

**DecisÃ£o Arquitetural:**

* B0: tecidos simples (ADI, DEB, MUS)
* B3: tecidos intermediÃ¡rios (LYM, MUC, NOR)
* B4: tecidos complexos (STR, TUM)

---

### 3. ValidaÃ§Ã£o com Cross-Validation em L Folds

**FundamentaÃ§Ã£o:** DemÅ¡ar (2006) recomenda o uso de validaÃ§Ã£o cruzada (e nÃ£o hold-out) para comparaÃ§Ãµes estatÃ­sticas confiÃ¡veis entre mÃºltiplos classificadores. Isso evita viÃ©s de particionamento e permite aplicaÃ§Ã£o dos testes de Friedman, Nemenyi e Wilcoxon.

**DecisÃ£o Arquitetural:** Cada modelo Ã© treinado com validaÃ§Ã£o cruzada estratificada (k=5). As prediÃ§Ãµes de todas as folds sÃ£o salvas para composiÃ§Ã£o do meta-modelo e para estatÃ­sticas.

---

## Estrutura Modular do Sistema

### `inference.py`

MÃ³dulo de inferÃªncia finalque carrega os modelos treinados por fold (ensemble interno), aplica prediÃ§Ãµes sobre uma imagem ou lote de imagens, combina as saÃ­das dos modelos com soft-voting ponderado (com base nos weights do config.yaml) e retorna a classe predita e a probabilidade agregada, com possibilidade de salvar o resultado em CSV/JSON.

ğŸ”§ 2. EstratÃ©gias e DecisÃµes TÃ©cnicas
ğŸ§  Modelos treinados por fold

    Para cada modelo (b0, b3, b4), teremos n_folds modelos (ex: 5).

    Para o ensemble final, vamos carregar todos os folds de cada modelo.

ğŸ” Justificativa:
Demsar (2006) e Wolpert (1992) indicam que o uso de ensembles reduz erro generalizado â€” especialmente ao explorar variaÃ§Ã£o entre folds. Isso garante robustez.


ğŸ§® 3. PrediÃ§Ã£o por modelo

Cada modelo serÃ¡ usado da seguinte forma:

output = model(image_tensor.unsqueeze(0).to("cuda"))
prob = torch.softmax(output, dim=1)

    Esse prob serÃ¡ coletado para cada modelo de cada fold.

    SerÃ¡ acumulado com pesos definidos no config.yaml.

ğŸ”— 4. EstratÃ©gia de CombinaÃ§Ã£o - Weighted Soft Voting
FÃ³rmula:
Pfinal(c)=1Zâˆ‘i=1Mwiâ‹…(1Kâˆ‘k=1KPik(c))
Pfinalâ€‹(c)=Z1â€‹i=1âˆ‘Mâ€‹wiâ€‹â‹…(K1â€‹k=1âˆ‘Kâ€‹Pikâ€‹(c))

    wiwiâ€‹: peso do modelo (ex: b0: 0.25, b3: 0.35, b4: 0.40)

    KK: nÃºmero de folds

    Pik(c)Pikâ€‹(c): probabilidade da classe cc predita pelo modelo ii no fold kk

    Z=âˆ‘wiZ=âˆ‘wiâ€‹: normalizaÃ§Ã£o

ğŸ“˜ ReferÃªncia: Ensemble learning literature (e.g., Opitz & Maclin, 1999; Kuncheva, 2004)

ğŸ“Š 5. SaÃ­da esperada

Para cada imagem:

    filename

    label_predito

    probabilidade_predita

    distribuiÃ§Ã£o completa (array com todas as probabilidades)

Opcionalmente:

    Salvar como .json, .csv, .xlsx ou exibir no console.

ğŸ§± 6. Componentes do inference.py
Componente	FunÃ§Ã£o
load_all_models()	Carrega todos os modelos treinados por fold, para cada EfficientNet
prepare_image()	Aplica preprocessamento (mesmo que no treino)
predict_image()	Faz forward em todos os modelos e aplica softmax
combine_predictions()	Aplica a fÃ³rmula do weighted soft voting
main()	Faz inferÃªncia sobre imagem ou diretÃ³rio de imagens
âš™ï¸ 7. Requisitos TÃ©cnicos

    torch, torchvision, albumentations, yaml, cv2, pandas

    Config compatÃ­vel com config.yaml

    ReutilizaÃ§Ã£o da pipeline de core.model, core.config_loader, core.augmentations



### DiretÃ³rio: `config/`

* `config.yaml`: define hiperparÃ¢metros globais, estruturas dos modelos e pesos do ensemble (Peng, 2011).

- model_name: efficientnet_b0, b3, b4
- dropout: entre 0.2â€“0.4 (Tellez et al., 2019)
- input_size: 224, 300, 380
- folds: 5 (Demsar, 2006 recomenda L-fold)
- weights: para o soft-voting (baseado na mÃ©dia da acurÃ¡cia por modelo)

### DiretÃ³rio: `core/`

#### `model.py`

- FÃ¡brica de modelos (EfficientNetClassifier) com parÃ¢metros configurÃ¡veis via config.yaml
- Define os modelos base que alimentam os ensembles
- Inclui o meta-modelo de stacking (Wolpert1992)
- Adapta a Ãºltima camada para 8 classes fixas (definidas no dataset HMU-GC-HE-30K)
- Aplica dropout para melhorar a regularizaÃ§Ã£o e evitar overfitting em poucos dados (Srivastava et al., 2014)
- Usa biblioteca `timm` para EfficientNet (Tan & Le, 2019)
- Define a classe `StackedEnsemble` com suporte a empilhamento

ğŸ§© Componentes e Responsabilidades
Classe / FunÃ§Ã£o	Responsabilidade
ModelFactory	Carregar arquitetura EfficientNet correta com base no config.yaml
SingleModel	Wrapper que encapsula o modelo + nome + metainformaÃ§Ã£o Ãºtil
load_pretrained_model()	Carrega EfficientNet via torchvision ou timm e aplica head final
get_model()	FunÃ§Ã£o principal: retorna modelo ajustado com nÃºmero correto de classes

âœ… Justificativas TÃ©cnicas (Literatura)
DecisÃ£o	Justificativa
Uso de EfficientNet-B0/B3/B4	Modelos leves e eficientes para histologia com bom desempenho em mÃºltiplos benchmarks (Tan & Le, 2019)
Treinamento individual por arquitetura	Segue estratÃ©gia definida por Wolpert (1992) de treinar especialistas independentes antes do ensemble
ModularizaÃ§Ã£o por ModelFactory	Facilita experimentaÃ§Ã£o, generalizaÃ§Ã£o e plugabilidade (DemÅ¡ar, 2006)
Uso de timm (opcional)	Biblioteca amplamente usada e otimizada para modelos SOTA (Wightman, 2021)

ğŸ“š ReferÃªncias:

- Tan & Le (2019): estrutura EfficientNet + trade-offs entre B0â€“B7
- Wolpert (1992): define a necessidade de combinar saÃ­das via metamodelo
- Liang et al. (2023), Echle et al. (2021): uso de EfficientNet para classificaÃ§Ã£o morfolÃ³gica
- Demsar (2006): define que todos os modelos devem ser comparÃ¡veis de forma justa â†’ output padronizado

#### `dataset.py`

- AbstraÃ§Ã£o do conjunto de amostras e deve operar sob Ã­ndices definidos externamente
- Implementa o dataset customizado que carrega os patches `TMEDataset`
- Usa `albumentations` para aplicar as transformacoes (Echle et al., 2021). As augmentations sÃ£o delegadas ao code/augmentations.py
- Constroi train_loader, val_loader via StratifiedKFold
- Cada instÃ¢ncia participa de treino e validaÃ§Ã£o em algum ponto (Demsar, 2006)
- StratifiedKFold preserva proporÃ§Ã£o de classes em cada fold (melhora confiabilidade)
-â€œA separaÃ§Ã£o clara entre dados e lÃ³gica de treino Ã© crÃ­tica para reprodutibilidade e extensibilidade em experimentos com mÃºltiplos folds.â€ â€” DemÅ¡ar, 2006; Bouthillier et al., NeurIPS Reproducibility Checklist

- Usamos data augmentations especÃ­ficas por classe histolÃ³gica, respaldada por trÃªs pilares:

  1- Preserva morfologia crÃ­tica
    - Evita distorÃ§Ãµes irreais em estruturas como nÃºcleos linfocitÃ¡rios ou fibras musculares
  2- Simula artefatos reais
    - Mimetiza variaÃ§Ãµes tÃ­picas de coloraÃ§Ã£o, corte e escaneamento (como sugerido por Tellez et al., 2019; Echle et al., 2021)
  3- Aprimora generalizaÃ§Ã£o
    - Treina o modelo para reconhecer variaÃ§Ãµes intra-classe fisiologicamente possÃ­veis, reduzindo overfitting (dos Santos et al., 2024)

 ğŸ” Essa estratÃ©gia Ã© inovadora, pois tratamos o microambiente tumoral como um espaÃ§o morfologicamente heterogÃªneo, considerando que cada tipo de tecido exige sensibilidades distintas de detecÃ§Ã£o (como regras de negÃ³cio especÃ­ficas).


*decisÃµes tecnicas*

dataset.py deve receber:
  -image_paths, labels
  - indices (ou is_train + fold_idx se quiser lÃ³gica interna opcional)
  - augmentation_strategy: AugmentationStrategy
  - config, para reuso de parÃ¢metros (ex: tamanho da imagem)
E deve aplicar a estratÃ©gia no __getitem__:
  - img = self.augmentation.get_transform(class_name)(image=np.array(img))["image"]

ğŸ§  Objetivos e responsabilidades da TumorDataset

A classe TumorDataset serÃ¡ o Ãºnico ponto do sistema com as seguintes responsabilidades:
Responsabilidade	Justificativa
Carregar imagens e rÃ³tulos a partir de uma lista	Reuso simples de imagens prÃ©-particionadas
Aplicar a estratÃ©gia de augmentation associada Ã  classe	Suporte Ã  lÃ³gica do ensemble morfolÃ³gico
Operar com Ã­ndices de treino/validaÃ§Ã£o passados por fora	Suporte a k-fold, mantendo controle externo no training.py
Permitir extensÃµes futuras (ex: WSI, ROI dinÃ¢micos)	Sustentabilidade arquitetural
ğŸ› ï¸ Requisitos arquiteturais

    ğŸ“ Caminho absoluto da imagem deve ser resolvido a partir de uma raiz (root_dir) + nome do arquivo (armazenado em CSV, XLSX etc.)

    ğŸ¯ A estratÃ©gia de augmentation vem de augmentations.py e serÃ¡ injetada via __init__, suportando Strategy Pattern

    ğŸ§ª O Ã­ndice de fold (opcional) e o split (train, val) Ã© controlado externamente

    ğŸ”’ Todas as transformaÃ§Ãµes devem usar albumentations com ToTensorV2()

    ğŸ§¼ Dataset deve ser robusto a erros e suportar debug (ex: imagem corrompida)

| CritÃ©rio                    | Atendido? | Justificativa                                                  |
| --------------------------- | --------- | -------------------------------------------------------------- |
| Separation of Concerns      | âœ…         | Augmentation, split e carregamento separados                   |
| ConfigurÃ¡vel via YAML       | âœ…         | EstratÃ©gia passada via objeto externo                          |
| Plugabilidade de EstratÃ©gia | âœ…         | Suporte completo ao Strategy Pattern                           |
| Suporte a Folds             | âœ…         | Usa Ã­ndices externos do StratifiedKFold                        |
| Extensibilidade futura      | âœ…         | Suporta outras fontes (ex: WSI), outros canais, outras tarefas |


#### `training.py`

* NÃºcleo operacional que define o pipeline de treinamento supervisionado dos modelos base com validaÃ§Ã£o cruzada estratificada
* Usa loop de epochs com treino -> validaÃ§Ã£o -> early stopping
* Salva o melhor modelo por fold
* Armazena mÃ©tricas em CSV
* Early stopping com paciÃªncia para evitar overfitting precoce (Echle et al., 2021)

ğŸ§± OBJETIVO DO training.py

O mÃ³dulo training.py Ã© responsÃ¡vel por:
| Responsabilidade                                                 | Justificativa                                                        |
| ---------------------------------------------------------------- | -------------------------------------------------------------------- |
| 1. Criar os folds e iterar por eles                              | Conforme validaÃ§Ã£o cruzada k-fold de DemÅ¡ar (2006)                   |
| 2. Treinar modelos individualmente (um por fold por arquitetura) | EstratÃ©gia de especialistas independentes de Wolpert (1992)          |
| 3. Salvar o melhor modelo por fold com nomeaÃ§Ã£o padronizada      | Reprodutibilidade e comparabilidade estatÃ­stica                      |
| 4. Avaliar desempenho em cada fold e registrar logs              | NecessÃ¡rio para anÃ¡lises pÃ³s-treino (e.g., ensemble ou estatÃ­sticas) |
| 5. Integrar: dataset.py, model.py, augmentations.py, config.yaml | ConexÃ£o de todas as partes do pipeline                               |


ğŸ“ VisÃ£o Geral da Arquitetura

training.py
â”œâ”€â”€ lÃª config.yaml
â”œâ”€â”€ para cada modelo (b0, b3, b4):
â”‚   â”œâ”€â”€ para cada fold (1 a k):
â”‚   â”‚   â”œâ”€â”€ divide dataset
â”‚   â”‚   â”œâ”€â”€ aplica augmentations com TumorDataset
â”‚   â”‚   â”œâ”€â”€ instancia modelo via ModelFactory
â”‚   â”‚   â”œâ”€â”€ treina por N epochs com early stopping
â”‚   â”‚   â”œâ”€â”€ avalia mÃ©trica (ex: accuracy ou F1)
â”‚   â”‚   â”œâ”€â”€ salva melhor modelo em /weights/
â”‚   â”‚   â””â”€â”€ loga resultados por fold
â””â”€â”€ salva csv com estatÃ­sticas de treino


ğŸ§© Componentes Integrados
| Componente             | MÃ³dulo de Origem             | FunÃ§Ã£o                                               |
| ---------------------- | ---------------------------- | ---------------------------------------------------- |
| `TumorDataset`         | `core/dataset.py`            | Aplicar augmentations especÃ­ficas por classe         |
| `ModelFactory`         | `core/model.py`              | Criar EfficientNet jÃ¡ configurado                    |
| `PerClassAugmentation` | `core/augmentations.py`      | EstratÃ©gia de transformaÃ§Ã£o morfolÃ³gica              |
| `config`               | `config.yaml`                | ParÃ¢metros como `batch_size`, `epochs`, `loss`, etc. |
| `torch.optim`          | PyTorch                      | Otimizador (Adam, SGD, etc.)                         |
| `torchmetrics`         | PyTorch Lightning (opcional) | MÃ©tricas de desempenho (accuracy, F1-score, etc.)    |
| `tqdm`                 | barra de progresso           | Progresso de treino                                  |

ğŸ” EstratÃ©gias Arquiteturais Fundamentadas

ğŸ“˜ Wolpert (1992): Diversidade e IndependÃªncia
    Cada fold Ã© um treinamento totalmente separado
    Sem mistura de pesos ou reuso de inferÃªncia entre modelos base
    O ensemble final Ã© feito apÃ³s o treinamento completo

ğŸ“˜ DemÅ¡ar (2006): EstatÃ­stica baseada em rank
    K-fold estratificado com mesma seed
    Mesma divisÃ£o para todos os modelos
    PrecisÃ£o, F1 ou outra mÃ©trica devem ser logadas por fold

ğŸ“˜ FundamentaÃ§Ã£o:

    DemÅ¡ar (2006): nÃ£o trata diretamente de early stopping, mas ressalta que comparaÃ§Ãµes justas requerem modelos otimizados com o mesmo critÃ©rio de avaliaÃ§Ã£o. O early stopping entra aqui como controle padronizado de "tÃ©rmino de otimizaÃ§Ã£o".

    Wolpert (1992): defende diversidade de especialistas. Modelos superajustados ao treino convergem para especializaÃ§Ãµes enviesadas â†’ early stopping preserva diversidade Ãºtil para ensemble.

    Na prÃ¡tica em histopatologia (CHD e artigos correlatos): early_stopping com patience=5â€“10 baseado na val_loss ou macro-F1 Ã© padrÃ£o (referÃªncias: CHD, Kather et al., 2019).

âœ… RecomendaÃ§Ã£o:

early_stopping:
  monitor: "val_macro_f1"
  mode: "max"
  patience: 7

Essa escolha Ã©:

    Alinhada com o objetivo de classificar tecidos variados com desempenho robusto (macro-F1)

    CompatÃ­vel com a diversidade esperada entre modelos no ensemble

    ReplicÃ¡vel nos logs por fold

âœ… 2. FunÃ§Ã£o de Custo
ğŸ” RevisÃ£o das opÃ§Ãµes:
FunÃ§Ã£o de Custo	Vantagem	Quando Usar
CrossEntropyLoss	Simples e eficaz para classes balanceadas	Base padrÃ£o â€” usada na CHD e EfficientNet originais
Focal Loss	Penaliza mais os erros em classes raras	Quando hÃ¡ desequilÃ­brio severo de classes
Label Smoothing	Suaviza targets â†’ evita overfitting local	Quando as classes sÃ£o semelhantes morfologicamente
ğŸ“˜ FundamentaÃ§Ã£o:

    Wolpert (1992): favorece arquiteturas que podem se especializar (ex: focal loss pode enviesar demais).

    DemÅ¡ar (2006): requer comparaÃ§Ã£o com controle de variabilidade â€” cross-entropy mantÃ©m baseline simples e replicÃ¡vel.

    CHD e Kather et al. usam CrossEntropyLoss com sucesso.

âœ… RecomendaÃ§Ã£o:

loss_function: "CrossEntropyLoss"

E opcionalmente:

label_smoothing: 0.0  # pode ser 0.1 em experimentos controlados


âœ… 3. MÃ©trica Principal
ğŸ¯ Alvo: refletir a performance em todas as classes de tecidos, nÃ£o sÃ³ nas mais fÃ¡ceis (como TUM).
ğŸ“˜ FundamentaÃ§Ã£o:

    DemÅ¡ar (2006): defende o uso de mÃ©tricas robustas para comparaÃ§Ã£o inter-modelos. MÃ©dia simples ou ponderada Ã© recomendada.

    Wolpert (1992): reforÃ§a o valor da diversidade e consistÃªncia dos especialistas.

    Macro-F1 Ã© a escolha predominante em estudos histopatolÃ³gicos (CHD, PanNuke, BACH), pois trata todas as classes com igual importÃ¢ncia.

âœ… RecomendaÃ§Ã£o:

metric: "macro_f1"


âœ… 5. Balanceamento de Classes
ğŸ“˜ FundamentaÃ§Ã£o:

    O dataset CHD possui equilÃ­brio em nÃºmero de imagens por classe, mas nÃ£o em complexidade morfolÃ³gica, conforme consta no [s41597-025-04489-9.pdf].

    PanNuke (2020) e Kather et al. discutem o problema de complexidade de classe como um fator de viÃ©s morfolÃ³gico, e sugerem:

        Data augmentation morfo-especÃ­fica (âœ… jÃ¡ aplicada)

        Uso de WeightedRandomSampler baseado em dificuldade ou confusÃ£o â€” MAS isso viola a premissa de diversidade dos especialistas em ensembles.

âœ… RecomendaÃ§Ã£o:

NÃ£o aplicar balanceamento artificial adicional no loader.
O ensemble + augmentations jÃ¡ sÃ£o estratÃ©gias consistentes e respeitam a independÃªncia dos modelos (Wolpert).

ğŸ§© Arquitetura Modular do training.py

training.py
â”œâ”€â”€ parse_args() â†’ model_name, fold_id
â”œâ”€â”€ carregar config.yaml
â”œâ”€â”€ preparar fold (train_idx, val_idx)
â”œâ”€â”€ criar datasets com augmentations
â”œâ”€â”€ carregar modelo com ModelFactory
â”œâ”€â”€ configurar otimizador, scheduler, etc
â”œâ”€â”€ executar epochs com early stopping
â”‚   â”œâ”€â”€ treinar 1 epoch
â”‚   â”œâ”€â”€ validar
â”‚   â”œâ”€â”€ logar mÃ©trica (macro-F1, loss)
â”‚   â”œâ”€â”€ salvar melhor modelo (por val_macro_f1)
â”œâ”€â”€ salvar:
â”‚   â”œâ”€â”€ checkpoint.pth
â”‚   â”œâ”€â”€ log.csv (loss, acc, f1 por epoch)
â”‚   â”œâ”€â”€ val_predictions.csv
â”‚   â””â”€â”€ metrics.json (macro-F1 final, best_epoch, etc)
â””â”€â”€ atualiza summary global (opcional)

ğŸ“‹ MÃ³dulos e Responsabilidades Conectadas
MÃ³dulo	FunÃ§Ã£o
dataset.py	Gera o TumorDataset com os Ã­ndices corretos para cada fold
model.py	ConstrÃ³i o modelo de acordo com o nome e configuraÃ§Ãµes
augmentations.py	Garante augmentations especÃ­ficas por classe
stats.py (futuro)	Pode calcular mÃ©tricas pÃ³s-treino (e.g., confusion matrix, F1 detalhado)
ğŸ› ï¸ Logging no Console

Vamos usar dois nÃ­veis de logging:

    logging padrÃ£o para salvar em arquivo (log por epoch e fold)

    tqdm para progresso visual no terminal (tempo estimado, perda atual etc.)

ConfiguraÃ§Ã£o de log no inÃ­cio do script:

import logging

def setup_logger(log_file):
    logging.basicConfig(
        filename=log_file,
        filemode='w',
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    formatter = logging.Formatter('%(message)s')
    console.setFormatter(formatter)
    logging.getLogger().addHandler(console)

âœ… Resumo das Garantias do training.py
Garantia	Como serÃ¡ feito
ExecuÃ§Ã£o modular e paralelizÃ¡vel	Recebe argumentos CLI: --model e --fold
Compatibilidade com config.yaml	Carregamento unificado e dinÃ¢mico
Outputs organizados e independentes	outputs/{model_name}/fold_{k}/...
Registro cientÃ­fico completo	log.csv, metrics.json, val_predictions.csv por fold
Reprodutibilidade	Todos os elementos controlados por config, inclusive seed e augmentation
ConexÃ£o com ensemble posterior	Modelos salvos organizadamente para uso posterior no ensemble

#### `evaluation.py`

* Avalia cada fold com: AcurÃ¡cia, Balanced Accuracy, Kappa, F1 (macro)
* Usa `sklearn.metrics` para facilitar integraÃ§Ã£o
* Balanced Accuracy para lidar com dataset desbalanceado (Haixiang et al., 2017)
* Usa Kappa para ter mais cuidado com acerto por acaso (Viera & Garrett, 2005)

#### `ensemble.py`

* Implementa dois tipos de ensemble: Soft voting ponderado / Stacked generalization (Wolpert, 1992)

* Soft voting: mÃ©dia ponderada das saÃ­das de softmax
* Stacked generalization:
    - input: concatenaÃ§Ã£o das saÃ­das softmax dos modelos base
    - modelo meta: regressÃ£o logÃ­stica ou MLP simples

* Wolpert (1992) mostra que empilhar modelos com um meta-aprendizado Ã© mais robusto que votos


#### `stats.py`

* Executa testes Friedman, Nemenyi e Wilcoxon (Demsar, 2006)
* Testa se o ensemble Ã© estatisticamente melhor que modelos individuais
* Usa `Orange.evaluation` ou `scipy.stats`
* Gera grÃ¡fico de ranking para o artigo usando Orange
* Demsar (2006) proÃ­be uso de ANOVA quando dados sÃ£o nÃ£o normais ou dependentes
* Nemenyi controla erro tipo I em mÃºltiplas comparaÃ§Ãµes (controle de FWER

#### `augmentations.py`

- ResponsÃ¡vel por centralizar e encapsular toda a lÃ³gica relacionada a transformaÃ§Ãµes visuais (data augmentation)
- Implementa a funÃ§Ã£o get_augmentation_by_class() com base em anÃ¡lise morfolÃ³gica
- Permite alternar entre transformaÃ§Ãµes padronizadas ou especÃ­ficas por classe
- ParametrizÃ¡vel via config.yaml

*DecisÃµes de implementaÃ§Ã£o*

- PadrÃ£o Strategy Pattern para vialbilizar estratÃ©gias de transformaÃ§Ãµes plugÃ¡vies e com interface comum (por classe, global, nenhuma, etc.) (Gamma et al. 1994)

- A etapa de transformaÃ§Ã£o morfolÃ³gica foi implementada com base no padrÃ£o Strategy de design de software, permitindo que diferentes estratÃ©gias de data augmentation sejam facilmente intercambiÃ¡veis e parametrizÃ¡veis por classe histolÃ³gica. Isso garante clareza, reprodutibilidade e possibilidade de generalizaÃ§Ã£o do sistema para outros domÃ­nios clÃ­nicos.
---

#### `metrics.py`

| Item                | Detalhes                                                                                      |
| ------------------- | --------------------------------------------------------------------------------------------- |
| ğŸ“ LocalizaÃ§Ã£o      | `ensemble_tme/core/metrics.py`                                                                |
| ğŸ¯ Responsabilidade | Calcular e registrar as mÃ©tricas quantitativas do modelo por **fold**, **classe**, **modelo** |
| ğŸ‘¥ Chamado por      | Diretamente de `training.py` apÃ³s cada `fold`                                                 |
| ğŸ“Š Exporta          | `.csv` e `.json` contendo:                                                                    |
| MÃ©trica               | Justificativa                                                                  |
| --------------------- | ------------------------------------------------------------------------------ |
| Accuracy              | Baseline para anÃ¡lise estatÃ­stica (DemÅ¡ar, 2006)                               |
| F1-score (macro)      | Ideal para avaliar desempenho multiclasse com desequilÃ­brio                    |
| F1-score (weighted)   | Compensa diferenÃ§a de frequÃªncia entre classes                                 |
| F1-score (por classe) | Permite anÃ¡lise de especializaÃ§Ã£o dos modelos (Wolpert, 1992)                  |
| Matriz de confusÃ£o    | Fundamental para identificar padrÃµes de erro e redundÃ¢ncia entre especialistas |

#### `visualization.py`

âœ… Objetivo das visualizaÃ§Ãµes

Mostrar com clareza, profundidade estatÃ­stica e apelo visual:

    O comportamento e aprendizado dos modelos ao longo das Ã©pocas.

    A performance por classe e por modelo.

    O comportamento entre folds e entre modelos, respeitando comparaÃ§Ãµes justas (DemÅ¡ar).

    Evidenciar onde o ensemble ganha, e o que cada modelo individual erra ou acerta.

    Facilitar a compreensÃ£o prÃ¡tica para o pÃºblico-alvo clÃ­nico (ex: patologistas, mÃ©dicos computacionais).

ğŸ§­ VisÃµes obrigatÃ³rias com base na literatura
1. ğŸ“‰ Curvas de aprendizado (loss, F1, acc por Ã©poca)

    ğŸ“Œ JÃ¡ geradas no training.py, sÃ£o obrigatÃ³rias.

    ğŸ‘¨â€ğŸ”¬ Servem para mostrar se houve overfitting, underfitting ou convergÃªncia.

    âœ… DemÅ¡ar (2006) reforÃ§a que anÃ¡lise temporal Ã© essencial em pipelines comparativos.

    âœ… Mostrar atÃ© onde o modelo foi capaz de aprender, inclusive o efeito do early stopping.

2. ğŸ“Š Matriz de confusÃ£o (por modelo)

    Ideal: uma matriz por modelo, agregada entre folds (normalizada e com valores absolutos).

    Serve para entender quais classes sÃ£o confundidas entre si.

    Muito Ãºtil para evidenciar falhas como:

        confusÃ£o entre TUM e DEB

        ou STR com MUS.

    ğŸ“Œ Importante para justificar decisÃµes clÃ­nicas futuras baseadas no modelo.

3. ğŸ¯ Curvas ROC + AUC (por classe e mÃ©dia macro/micro)

    Um grÃ¡fico por modelo, contendo 8 curvas (uma para cada classe), alÃ©m da curva macro e micro.

    Indica quÃ£o bem o modelo separa as classes, mesmo em desequilÃ­brio de decisÃ£o binÃ¡ria.

    Referenciado amplamente em:

        Litjens et al., 2017 (MedIA)

        Wang et al., 2020 (EfficientNet for colorectal cancer classification)

4. ğŸ“¦ Boxplot (ou Violin Plot) de macro F1 por fold e por modelo

    Permite comparar a distribuiÃ§Ã£o do desempenho ao longo dos folds.

    ğŸ“Œ DemÅ¡ar (2006) recomenda fortemente boxplots e ranks para comparar modelos em mÃºltiplos datasets/folds.

    Pode ser estendido para rank plot se estivermos comparando mais de trÃªs variantes.

5. ğŸ§  GrÃ¡fico de barras com desempenho por classe e por modelo

    Para evidenciar que alguns modelos funcionam melhor para certas classes (ex: B3 para LYM).

    Usar F1-score por classe como base.

ğŸ“ VisÃµes complementares (opcional, mas recomendadas)
6. ğŸ§© GrÃ¡fico de contribuiÃ§Ã£o dos modelos no ensemble

    Um radar chart ou stacked bar para mostrar como os modelos individuais contribuem por classe.

    Relaciona com Wolpert (1992): como as "biases" individuais do modelo formam um sistema mais robusto.

7. ğŸ“ˆ Heatmaps de saliÃªncia / Grad-CAM (qualitativos)

    Uma imagem por classe mostrando onde o modelo foca para decidir.

    Ãštil em artigos voltados para aplicaÃ§Ã£o mÃ©dica e justificativa de decisÃµes.

    Pode vir como apÃªndice ou suplemento visual.

âœ… Resumo consolidado: o que devemos gerar
VisualizaÃ§Ã£o	RelevÃ¢ncia	Para quem serve?	FundamentaÃ§Ã£o
Curvas de treino (loss/F1/acc)	Alta	Pesquisadores de IA	DemÅ¡ar 2006, prÃ¡tica comum
Matriz de confusÃ£o (por modelo)	Alta	Patologistas, IA	Explica erros e confusÃµes
Curvas ROC + AUC (por classe)	Alta	IA, revisÃ£o por pares	PadrÃ£o clÃ­nico e comparativo
Boxplot F1 macro (por fold/modelo)	Alta	Pesquisadores, editores	DemÅ¡ar 2006, comparaÃ§Ã£o estatÃ­stica
Barras por classe e modelo	Alta	ComparaÃ§Ã£o intra-classe	DiagnÃ³stico diferencial
ContribuiÃ§Ã£o dos modelos	MÃ©dia	Para justificar o ensemble	Wolpert 1992
Grad-CAM	MÃ©dia	Patologistas, visual clÃ­nico	Explicabilidade

### Diretorio: `scripts/`

#### `run_all_folds.py`

ğŸ§  O que esse script faz?

| Etapa                     | DescriÃ§Ã£o                                                           |
| ------------------------- | ------------------------------------------------------------------- |
| ğŸ”„ `load_config()`        | LÃª o `config.yaml` para saber quais modelos e quantos folds existem |
| ğŸ” `itertools.product()`  | Gera todas as combinaÃ§Ãµes `(modelo, fold)`                          |
| ğŸ¯ `CUDA_VISIBLE_DEVICES` | Atribui cada job a uma GPU disponÃ­vel                               |
| âš™ï¸ `subprocess.Popen`     | Executa `training.py` como subprocesso com redirecionamento de log  |
| ğŸ“ `logs/*.out`           | Cada job salva seu log em um arquivo independente                   |
| ğŸ›‘ `--dry-run`            | Permite simular sem executar (Ãºtil para debug)                      |

âœ… Exemplo de execuÃ§Ã£o:

python scripts/run_all_folds.py --gpus 2 --config config/config.yaml

- ExecutarÃ¡ os folds usando 2 GPUs de forma rotativa e criarÃ¡ logs em logs/efficientnet_b3_fold4.out

#### `evaluate_ensemble.py`

Executa o ensemble morfolÃ³gico a partir dos modelos treinados, aplica a inferÃªncia sobre os dados de validaÃ§Ã£o ou teste, e gera todas as mÃ©tricas e visualizaÃ§Ãµes automaticamente.

ğŸ§ª Como executar
Com os modelos jÃ¡ treinados e salvos em outputs/efficientnet_b*/fold_*/checkpoint.pth, execute:

python scripts/evaluate_ensemble.py --config config/config.yaml --csv data/test.csv

ğŸ“‚ Estrutura de saÃ­da

O script criarÃ¡ a pasta:

outputs/
 â””â”€â”€ ensemble/
      â”œâ”€â”€ ensemble_summary.json          # F1 e ACC do ensemble
      â”œâ”€â”€ confusion_matrix.png
      â”œâ”€â”€ roc_curve.png
      â””â”€â”€ classification_report.csv


#### `run_statistical_analysis.py`

- Garante execuÃ§Ã£o isolada e padronizada;
- Pode ser facilmente reaproveitado em qualquer experimento;
- Gera automaticamente tabelas e grÃ¡ficos de anÃ¡lise estatÃ­stica com base na literatura (DemÅ¡ar, Wolpert etc.).

ğŸ“Œ Como usar

No terminal:

python scripts/run_statistical_analysis.py \
    --csv outputs/fold_metrics.csv \
    --baseline efficientnet_b0 \
    --metric f1 \
    --output-dir outputs/stats

#### `run_inference.py`

ğŸ§  O que o script faz:

    LÃª o config.yaml

    Permite inferir uma Ãºnica imagem (--image) ou todas as de uma pasta (--folder)

    Usa a funÃ§Ã£o predict_image() definida em inference.py

    Imprime os resultados no console (classe final + score)

    Salva opcionalmente os resultados num CSV (--save)
    
ğŸ’¡ Exemplo de uso:

# InferÃªncia de uma Ãºnica imagem
python scripts/run_inference.py --image test_images/ADI_1.png

# InferÃªncia em uma pasta + salvar CSV
python scripts/run_inference.py --folder test_images --save outputs/inference_results.csv


### DiretÃ³rio: `experiments/`

#### `run_experiment.py`

* Roda o treinamento de todos os modelos base
* Salva as prediÃ§Ãµes por fold
* Treina o meta-modelo com as prediÃ§Ãµes
* Avalia e executa os testes estatÃ­sticos

---

## Tecnologias Selecionadas

| Tecnologia          | Justificativa                                              |
| ------------------- | ---------------------------------------------------------- |
| PyTorch + TIMM      | Suporte Ã s arquiteturas EfficientNet com pretrained models |
| scikit-learn        | MÃ©tricas, modelos leves (LogReg) para stacking             |
| albumentations      | Augmentations sensÃ­veis Ã  histologia (Tellez et al., 2019) |
| pandas              | ManipulaÃ§Ã£o de dados e tabelas de resultados               |
| matplotlib / Orange | VisualizaÃ§Ã£o de rankings com Nemenyi                       |

---

## SaÃ­das Esperadas

* `outputs/scores.csv`: acurÃ¡cia e F1 por modelo/fold
* `outputs/ranks.png`: ranking estatÃ­stico com teste de Nemenyi
* `outputs/checkpoints/`: pesos salvos por modelo/fold
* `README.md`: documentaÃ§Ã£o arquitetural completa para escrita de artigo

---

ğŸ”„ Fluxograma de ExecuÃ§Ã£o Geral

```
INÃCIO
  â”‚
  â”œâ”€â”€> 1. Carregar configuraÃ§Ã£o (config.yaml)
  â”‚        â””â”€â”€ model_name, input_size, lr, dropout, folds
  â”‚
  â”œâ”€â”€> 2. Construir modelo base (EfficientNet-B0/B3/B4)
  â”‚        â””â”€â”€ via model.py -> EfficientNetClassifier
  â”‚
  â”œâ”€â”€> 3. Carregar dataset com aug. e labels (dataset.py)
  â”‚        â””â”€â”€ ConstruÃ§Ã£o por fold (StratifiedKFold)
  â”‚
  â”œâ”€â”€> 4. Treinamento por fold (training.py)
  â”‚        â”œâ”€â”€ Loop: treino/validaÃ§Ã£o por fold
  â”‚        â””â”€â”€ Checkpoint do melhor modelo (early stopping)
  â”‚
  â”œâ”€â”€> 5. AvaliaÃ§Ã£o por fold (evaluation.py)
  â”‚        â””â”€â”€ MÃ©tricas padronizadas (acc, F1, kappa)
  â”‚
  â”œâ”€â”€> 6. Registro dos resultados (scores.csv)
  â”‚
  â”œâ”€â”€> 7. ComparaÃ§Ã£o estatÃ­stica (stats.py)
  â”‚        â”œâ”€â”€ Teste de Friedman + post-hoc Nemenyi
  â”‚        â””â”€â”€ GeraÃ§Ã£o de grÃ¡fico de ranks
  â”‚
  â””â”€â”€> 8. GeraÃ§Ã£o de ensemble (ensemble.py)
            â”œâ”€â”€ Soft-voting
            â””â”€â”€ Stacked generalization (Wolpert)
FIM

```

ğŸ—ï¸ Fluxo arquitetural

```
               +------------------+
               | config.yaml      |
               +------------------+
                        |
                Load config (main.py)
                        â†“
               +------------------+
               | training.py      | â† controla StratifiedKFold (sklearn)
               +------------------+
                        |
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â†“                       â†“
     Fold indices (train/test)   Fold loop
             â†“                       â†“
     +-----------------+       +-------------------+
     | dataset.py      |  â†’    | model.py          |
     | recebe Ã­ndices  |       | instancia modelo  |
     | aplica aug por  |       +-------------------+
     | classe          |
     +-----------------+

```

---

ğŸ§© Arquivos .py e suas Responsabilidades

| Arquivo                       | Responsabilidade Principal                                                              | Chamado por                             |
| ----------------------------- | --------------------------------------------------------------------------------------- | --------------------------------------- |
| `training.py`                 | Executar o ciclo de treinamento de um modelo por fold                                   | (n/a - ponto de entrada)                |
| `config_loader.py`            | Carregar e gerenciar configuraÃ§Ãµes do `config.yaml`                                     | `training.py`, `model.py`, `dataset.py` |
| `dataset.py`                  | Gerar datasets para treino e validaÃ§Ã£o com augmentations por classe e fold              | `training.py`                           |
| `augmentations.py`            | Fornecer estratÃ©gia de transformaÃ§Ã£o morfolÃ³gica por classe                             | `dataset.py`                            |
| `model.py`                    | Construir o modelo (`EfficientNet`) com as configuraÃ§Ãµes de input e dropout especÃ­ficas | `training.py`                           |
| `metrics.py` (a ser criado)   | Calcular mÃ©tricas: accuracy, macro-F1, matriz de confusÃ£o                               | `training.py`                           |
| `logger.py` (opcional)        | Criar logs de arquivo + console (se nÃ£o for feito inline)                               | `training.py`                           |
| `visualization.py` (opcional) | Gerar grÃ¡ficos para uso no artigo (curvas de loss, F1, acc)                             | `training.py`                           |
| `stats.py` (opcional)         | Agregador de mÃ©tricas globais apÃ³s treino de todos os folds                             | Fase posterior ao ensemble              |

ğŸ”— Fluxo de RelaÃ§Ã£o entre MÃ³dulos

```
training.py
â”œâ”€â”€ parse_args() â† CLI
â”œâ”€â”€ load_config() â† config_loader.py
â”œâ”€â”€ select_model_config() â† config["models"]
â”œâ”€â”€ StratifiedKFold â† scikit-learn
â”‚   â””â”€â”€ Dataset(indexes) â† dataset.py
â”‚       â””â”€â”€ AugmentationStrategy â† augmentations.py
â”œâ”€â”€ build_model() â† model.py
â”œâ”€â”€ optimizer/scheduler/criterion â† torch + config
â”œâ”€â”€ train loop:
â”‚   â”œâ”€â”€ forward, backward, step
â”‚   â”œâ”€â”€ validation loop:
â”‚       â”œâ”€â”€ metrics â† metrics.py
â”‚       â””â”€â”€ logs â† CSV + console
â”‚   â”œâ”€â”€ early stopping
â”‚   â””â”€â”€ save_best_model()
â”œâ”€â”€ save_metrics(), predictions.csv
â””â”€â”€ plot_curves() â† visualization.py

```

## ReferÃªncias BibliogrÃ¡ficas

* Tan, M., & Le, Q. V. (2019). EfficientNet: Rethinking model scaling for CNNs. ICML.
* Tellez, D. et al. (2019). Whole-slide mitosis detection in H\&E breast histology using PHH. Medical Image Analysis.
* Wolpert, D. H. (1992). Stacked generalization. Neural Networks, 5(2), 241-259.
* DemÅ¡ar, J. (2006). Statistical comparisons of classifiers over multiple data sets. JMLR.
* Echle, A. et al. (2021). Deep learning in cancer pathology: a new generation of clinical biomarkers. The Lancet Oncology.
* Liang, H. et al. (2023). Deep learning supported discovery of biomarkers for improved cancer immunotherapy. Nat Mach Intell.
