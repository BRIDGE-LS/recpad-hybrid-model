train_loss,val_loss,val_macro_f1
1.1821697951129286,0.7951855458510227,0.7005652720999378
0.8110137373438837,0.7125680333910844,0.7219833232112892
0.6928230978759211,0.6752205730630801,0.744091032555404
0.5912341782511966,0.6819682295505817,0.7451166770289784
0.4885163288036778,0.6855567365502699,0.7498325839281116
0.4063914553441854,0.7350989781893217,0.7482758751751745
0.316955843557314,0.7595691162806291,0.7529487575376358
0.2599265619461212,0.8236747720111639,0.74809588079825
0.2155788005700761,0.8911131218839914,0.7421201110474728
0.17032816070957937,0.9662958526840577,0.749829284574459
0.146594555020227,0.9520628392696381,0.7468901078953072
0.12798136936088875,1.0467311597787416,0.7482680260976668
0.11307217496157573,1.0345586291108375,0.7415050810512661
0.09765033305390405,1.1347814900848345,0.7374567702968592
0.09431365472569841,1.0852004384383178,0.7415318164973341
0.08366072855460048,1.090326182009318,0.749434187585168
0.07201490526408996,1.2134236831504566,0.7385038648278454
0.06756653520877169,1.1730733649470868,0.745374518873609
0.061727591804474125,1.2638712517726116,0.7442409980925426
0.05693675162690239,1.2684384510303155,0.7417461943470949
0.05363708757181894,1.2462676313443062,0.7463186394639598
0.052449414050095816,1.2704474370449017,0.74946839643443
